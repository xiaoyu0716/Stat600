# 查看LASSO选择的变量
lasso_coef <- coef(cv_lasso, s = "lambda.min")
print(lasso_coef)
# 选择非零系数的变量（包括交互项）
selected_vars <- rownames(lasso_coef)[which(lasso_coef != 0)]
selected_vars <- selected_vars[selected_vars != "(Intercept)"]
print("LASSO选择的变量和交互项：")
print(selected_vars)
# 交叉验证选择最佳lambda，alpha设为0表示岭回归
cv_ridge <- cv.glmnet(x, y, family = "binomial", alpha = 0)
best_lambda_ridge <- cv_ridge$lambda.min
# 拟合岭回归模型
ridge_model_2 <- glmnet(x, y, family = "binomial", alpha = 0, lambda = best_lambda_ridge)
ridge_coef <- coef(ridge_model)
print(ridge_coef)
# 选择非零系数的变量（包括交互项）
# choosing some items
beta = 0.05
selected_vars_r <- rownames(ridge_coef)[which(abs(ridge_coef) >beta)]
selected_vars_r <- selected_vars_r[selected_vars_r != "(Intercept)"]
# print("LASSO选择的变量和交互项：")
print(selected_vars_r)
library(dplyr)
# library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q2_test <- q2_test[complete.cases(q2_test), ]
factor_design <-  q2_test %>% select(-depressed) %>% names()
#
# predictors <- names(q2_test)[names(q2_test) != "depressed"]
# 创建公式，包括所有两两交叉项
formula <- as.formula(paste("~ (", paste(factor_design, collapse = " + "), ")^2"))
# 生成设计矩阵，自动处理因子变量和交叉项
design_matrix <- model.matrix(formula, data = q2_test)[, -1]  # 去掉截距列
# 转换为数据框
design_df <- as.data.frame(design_matrix)
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q2_test,type = "response")
pred_probs_L <- predict(cv_lasso, newx = design_matrix, type = "response")
pred_probs_R <- predict(ridge_model, newx = design_matrix, type = "response")
correct_ratio_2 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
# 将预测概率转换为类别
threshold <- 0.1
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_2[1] <- sum(abs(pred_classes_G-(as.numeric(q2_test$depressed))))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_2[2] <- sum(abs(pred_classes_L-(as.numeric(q2_test$depressed))))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_2[3] <- sum(abs(pred_classes_R-(as.numeric(q2_test$depressed))))/length(pred_classes_R)
print(correct_ratio_2)
library(dplyr)
# library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q2_test <- q2_test[complete.cases(q2_test), ]
factor_design <-  q2_test %>% select(-depressed) %>% names()
#
# predictors <- names(q2_test)[names(q2_test) != "depressed"]
# 创建公式，包括所有两两交叉项
formula <- as.formula(paste("~ (", paste(factor_design, collapse = " + "), ")^2"))
# 生成设计矩阵，自动处理因子变量和交叉项
design_matrix <- model.matrix(formula, data = q2_test)[, -1]  # 去掉截距列
# 转换为数据框
design_df <- as.data.frame(design_matrix)
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q2_test,type = "response")
pred_probs_L <- predict(cv_lasso, newx = design_matrix, type = "response")
pred_probs_R <- predict(ridge_model, newx = design_matrix, type = "response")
correct_ratio_2 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
# 将预测概率转换为类别
threshold <- 0.05
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_2[1] <- sum(abs(pred_classes_G-(as.numeric(q2_test$depressed))))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_2[2] <- sum(abs(pred_classes_L-(as.numeric(q2_test$depressed))))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_2[3] <- sum(abs(pred_classes_R-(as.numeric(q2_test$depressed))))/length(pred_classes_R)
print(correct_ratio_2)
library("tidyr")
df = read.csv('data.csv')
set.seed(600)
train = sample(c(TRUE, FALSE), nrow(df), rep=TRUE, prob=c(0.8, 0.2))
df_train = df[train, ]
df_test = df[!train, ]
# check if NA
colSums(is.na(df))
# rowSums(is.na(df))
df <- df %>% drop_na(names(df))
# 将需要的变量转换为因子
categorical_vars <- names(df)[sapply(df,is.integer)]
df[categorical_vars] <- lapply(df[categorical_vars], factor)
# 将响应变量转换为因子
df$depressed <- factor(df$depressed, levels = c(0,1))
#normalize continuous covariates
con_vars <- names(df)[sapply(df,is.numeric)]
df[con_vars] <- scale(df[con_vars])
library(dplyr)
#Q1 Depression Screener (DBQ)
q1 <- df[df$DBQ197!=4,] %>%
select(contains("DBQ"),depressed)
# names()
# q1 <- q1[q1_var$DBQ197!=4,]
q1_var <- q1[train,]
# names()
# q1_var <- q1_var[q1_var$DBQ197!=4,]
q1_test <- q1[!train,]
# 先拟合一个初始模型
library(car)
initial_model <- glm(depressed ~ ., data = q1_var, family = binomial)
# 计算VIF
vif_values <- vif(initial_model)
vif_values
# 通常，VIF > 5 或 10 表示存在多重共线性，需要处理
# 逐步回归（双向选择）
step_model <- step(initial_model, direction = "both")
summary(step_model)
library(glmnet)
q1_var <- q1_var[complete.cases(q1_var), ]
# 准备数据
x <- model.matrix(depressed ~ ., q1_var)[,-1]
y <- q1_var$depressed
# 交叉验证选择最佳lambda
cv_lasso <- cv.glmnet(x, y, family = "binomial", alpha = 1)
best_lambda <- cv_lasso$lambda.min
# 拟合LASSO模型
lasso_model <- glmnet(x, y, family = "binomial", alpha = 1, lambda = best_lambda)
coef(lasso_model)
# 交叉验证选择最佳lambda，alpha设为0表示岭回归
cv_ridge <- cv.glmnet(x, y, family = "binomial", alpha = 0)
best_lambda_ridge <- cv_ridge$lambda.min
# 拟合岭回归模型
ridge_model <- glmnet(x, y, family = "binomial", alpha = 0, lambda = best_lambda_ridge)
coef(ridge_model)
# 加载必要的包
library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.2
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
print(correct_ratio_1)
# 加载必要的包
library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.1
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
print(correct_ratio_1)
(as.numeric(q1_test$depressed)
)
# 加载必要的包
library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.05
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
print(correct_ratio_1)
# 加载必要的包
library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.1
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
print(correct_ratio_1)
# 加载必要的包
library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.2
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
print(correct_ratio_1)
# 交叉验证选择最佳lambda，alpha设为0表示岭回归
cv_ridge <- cv.glmnet(x, y, family = "binomial", alpha = 0)
best_lambda_ridge <- cv_ridge$lambda.min
# 拟合岭回归模型
ridge_model_2 <- glmnet(x, y, family = "binomial", alpha = 0, lambda = best_lambda_ridge)
ridge_coef <- coef(ridge_model)
print(ridge_coef)
# 选择非零系数的变量（包括交互项）
# choosing some items
beta = 0.05
selected_vars_r <- rownames(ridge_coef)[which(abs(ridge_coef) >beta)]
selected_vars_r <- selected_vars_r[selected_vars_r != "(Intercept)"]
# print("LASSO选择的变量和交互项：")
print(selected_vars_r)
# 构建全模型（含所有两两交互项）
full_model <- lm(depressed ~ .^2, data = q2_var)
# 构建空模型
empty_model <- lm(depressed ~ 1, data = q2_var)
# 逐步选择（双向）
step_model_2 <- step(empty_model,
scope = list(lower = empty_model, upper = full_model),
direction = "both",
trace = FALSE)
# 查看最终模型
summary(step_model_2)
library(dplyr)
# library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q2_test <- q2_test[complete.cases(q2_test), ]
factor_design <-  q2_test %>% select(-depressed) %>% names()
#
# predictors <- names(q2_test)[names(q2_test) != "depressed"]
# 创建公式，包括所有两两交叉项
formula <- as.formula(paste("~ (", paste(factor_design, collapse = " + "), ")^2"))
# 生成设计矩阵，自动处理因子变量和交叉项
design_matrix <- model.matrix(formula, data = q2_test)[, -1]  # 去掉截距列
# 转换为数据框
design_df <- as.data.frame(design_matrix)
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model_2,newdata = q2_test,type = "response")
pred_probs_L <- predict(cv_lasso, newx = design_matrix, type = "response")
# 创建模型矩阵，包括所有两两交互项
x <- model.matrix(depressed ~ .^2, data = q2_var)[,-1]
y <- q2_var$depressed
# 拟合LASSO模型
# set.seed(123)
cv_lasso_2 <- cv.glmnet(x, y, alpha = 1)
# 获取最佳lambda
best_lambda <- cv_lasso$lambda.min
print(paste("最佳 lambda:", best_lambda))
# 查看LASSO选择的变量
lasso_coef <- coef(cv_lasso, s = "lambda.min")
print(lasso_coef)
# 选择非零系数的变量（包括交互项）
selected_vars <- rownames(lasso_coef)[which(lasso_coef != 0)]
selected_vars <- selected_vars[selected_vars != "(Intercept)"]
print("LASSO选择的变量和交互项：")
print(selected_vars)
library(dplyr)
# library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q2_test <- q2_test[complete.cases(q2_test), ]
factor_design <-  q2_test %>% select(-depressed) %>% names()
#
# predictors <- names(q2_test)[names(q2_test) != "depressed"]
# 创建公式，包括所有两两交叉项
formula <- as.formula(paste("~ (", paste(factor_design, collapse = " + "), ")^2"))
# 生成设计矩阵，自动处理因子变量和交叉项
design_matrix <- model.matrix(formula, data = q2_test)[, -1]  # 去掉截距列
# 转换为数据框
design_df <- as.data.frame(design_matrix)
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model_2,newdata = q2_test,type = "response")
pred_probs_L <- predict(cv_lasso_2, newx = design_matrix, type = "response")
pred_probs_R <- predict(ridge_model_2, newx = design_matrix, type = "response")
pred_probs_G <- predict.glm(step_model_2,newdata = q2_test,type = "response")
pred_probs_L <- predict(cv_lasso_2, newx = design_matrix, type = "response")
pred_probs_R <- predict(ridge_model_2, newx = q2_test, type = "response")
summary(ridge_model_2)
ridge_model_2 <- glmnet(x, y, family = "binomial", alpha = 0, lambda = best_lambda_ridge)
ridge_coef <- coef(ridge_model_2)
print(ridge_coef)
pred_probs_R <- predict(ridge_model_2, newx = q2_test, type = "response")
library(dplyr)
# library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q2_test <- q2_test[complete.cases(q2_test), ]
factor_design <-  q2_test %>% select(-depressed) %>% names()
#
# predictors <- names(q2_test)[names(q2_test) != "depressed"]
# 创建公式，包括所有两两交叉项
formula <- as.formula(paste("~ (", paste(factor_design, collapse = " + "), ")^2"))
# 生成设计矩阵，自动处理因子变量和交叉项
design_matrix <- model.matrix(formula, data = q2_test)[, -1]  # 去掉截距列
# 转换为数据框
design_df <- as.data.frame(design_matrix)
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model_2,newdata = q2_test,type = "response")
pred_probs_L <- predict(cv_lasso_2, newx = design_matrix, type = "response")
pred_probs_R <- predict(ridge_model_2, newx = design_matrix, type = "response")
correct_ratio_2 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
# 将预测概率转换为类别
threshold <- 0.05
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_2[1] <- sum(abs(pred_classes_G-(as.numeric(q2_test$depressed))))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_2[2] <- sum(abs(pred_classes_L-(as.numeric(q2_test$depressed))))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_2[3] <- sum(abs(pred_classes_R-(as.numeric(q2_test$depressed))))/length(pred_classes_R)
print(correct_ratio_2)
library(dplyr)
# library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q2_test <- q2_test[complete.cases(q2_test), ]
factor_design <-  q2_test %>% select(-depressed) %>% names()
#
# predictors <- names(q2_test)[names(q2_test) != "depressed"]
# 创建公式，包括所有两两交叉项
formula <- as.formula(paste("~ (", paste(factor_design, collapse = " + "), ")^2"))
# 生成设计矩阵，自动处理因子变量和交叉项
design_matrix <- model.matrix(formula, data = q2_test)[, -1]  # 去掉截距列
# 转换为数据框
design_df <- as.data.frame(design_matrix)
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model_2,newdata = q2_test,type = "response")
pred_probs_L <- predict(cv_lasso_2, newx = design_matrix, type = "response")
pred_probs_R <- predict(ridge_model_2, newx = design_matrix, type = "response")
correct_ratio_2 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
# 将预测概率转换为类别
threshold <- 0.1
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_2[1] <- sum(abs(pred_classes_G-(as.numeric(q2_test$depressed))))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_2[2] <- sum(abs(pred_classes_L-(as.numeric(q2_test$depressed))))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_2[3] <- sum(abs(pred_classes_R-(as.numeric(q2_test$depressed))))/length(pred_classes_R)
print(correct_ratio_2)
library(dplyr)
# library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q2_test <- q2_test[complete.cases(q2_test), ]
factor_design <-  q2_test %>% select(-depressed) %>% names()
#
# predictors <- names(q2_test)[names(q2_test) != "depressed"]
# 创建公式，包括所有两两交叉项
formula <- as.formula(paste("~ (", paste(factor_design, collapse = " + "), ")^2"))
# 生成设计矩阵，自动处理因子变量和交叉项
design_matrix <- model.matrix(formula, data = q2_test)[, -1]  # 去掉截距列
# 转换为数据框
design_df <- as.data.frame(design_matrix)
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model_2,newdata = q2_test,type = "response")
pred_probs_L <- predict(cv_lasso_2, newx = design_matrix, type = "response")
pred_probs_R <- predict(ridge_model_2, newx = design_matrix, type = "response")
correct_ratio_2 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
# 将预测概率转换为类别
threshold <- 0.2
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_2[1] <- sum(abs(pred_classes_G-(as.numeric(q2_test$depressed))))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_2[2] <- sum(abs(pred_classes_L-(as.numeric(q2_test$depressed))))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_2[3] <- sum(abs(pred_classes_R-(as.numeric(q2_test$depressed))))/length(pred_classes_R)
print(correct_ratio_2)
names(qq1)
names(q1)
