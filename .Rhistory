library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.05
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
# print(correct_ratio_1)
A = pred_classes_G
B = as.numeric(q1_test$depressed)-1
# 计算 True Positives (TP)、False Positives (FP)、True Negatives (TN)、False Negatives (FN)
TP <- sum((A == 1) & (B == 1))
FP <- sum((A == 1) & (B == 0))
TN <- sum((A == 0) & (B == 0))
FN <- sum((A == 0) & (B == 1))
# 计算 FDR
if((TP + FP) > 0) {
FDR <- FP / (TP + FP)
} else {
FDR <- NA
warning("没有预测为阳性的样本（A = 1），无法计算 FDR。")
}
# 计算 Power
if(TP + FN > 0) {
Power <- TP / (TP + FN)
} else {
Power <- NA
warning("没有实际为阳性的样本（B = 1），无法计算 Power。")
}
# 计算 Accuracy
Accuracy <- (TP + TN) / (TP + FP + TN + FN)
# 打印结果
cat(sprintf("False Discovery Rate (FDR): %.2f%%\n", FDR * 100))
cat(sprintf("Power: %.2f%%\n", Power * 100))
cat(sprintf("Accuracy: %.2f%%\n", Accuracy * 100))
# 加载必要的包
library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.01
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
# print(correct_ratio_1)
A = pred_classes_G
B = as.numeric(q1_test$depressed)-1
# 计算 True Positives (TP)、False Positives (FP)、True Negatives (TN)、False Negatives (FN)
TP <- sum((A == 1) & (B == 1))
FP <- sum((A == 1) & (B == 0))
TN <- sum((A == 0) & (B == 0))
FN <- sum((A == 0) & (B == 1))
# 计算 FDR
if((TP + FP) > 0) {
FDR <- FP / (TP + FP)
} else {
FDR <- NA
warning("没有预测为阳性的样本（A = 1），无法计算 FDR。")
}
# 计算 Power
if(TP + FN > 0) {
Power <- TP / (TP + FN)
} else {
Power <- NA
warning("没有实际为阳性的样本（B = 1），无法计算 Power。")
}
# 计算 Accuracy
Accuracy <- (TP + TN) / (TP + FP + TN + FN)
# 打印结果
cat(sprintf("False Discovery Rate (FDR): %.2f%%\n", FDR * 100))
cat(sprintf("Power: %.2f%%\n", Power * 100))
cat(sprintf("Accuracy: %.2f%%\n", Accuracy * 100))
# 加载必要的包
library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.1
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
# print(correct_ratio_1)
A = pred_classes_G
B = as.numeric(q1_test$depressed)-1
# 计算 True Positives (TP)、False Positives (FP)、True Negatives (TN)、False Negatives (FN)
TP <- sum((A == 1) & (B == 1))
FP <- sum((A == 1) & (B == 0))
TN <- sum((A == 0) & (B == 0))
FN <- sum((A == 0) & (B == 1))
# 计算 FDR
if((TP + FP) > 0) {
FDR <- FP / (TP + FP)
} else {
FDR <- NA
warning("没有预测为阳性的样本（A = 1），无法计算 FDR。")
}
# 计算 Power
if(TP + FN > 0) {
Power <- TP / (TP + FN)
} else {
Power <- NA
warning("没有实际为阳性的样本（B = 1），无法计算 Power。")
}
# 计算 Accuracy
Accuracy <- (TP + TN) / (TP + FP + TN + FN)
# 打印结果
cat(sprintf("False Discovery Rate (FDR): %.2f%%\n", FDR * 100))
cat(sprintf("Power: %.2f%%\n", Power * 100))
cat(sprintf("Accuracy: %.2f%%\n", Accuracy * 100))
# 加载必要的包
library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.2
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
# print(correct_ratio_1)
A = pred_classes_G
B = as.numeric(q1_test$depressed)-1
# 计算 True Positives (TP)、False Positives (FP)、True Negatives (TN)、False Negatives (FN)
TP <- sum((A == 1) & (B == 1))
FP <- sum((A == 1) & (B == 0))
TN <- sum((A == 0) & (B == 0))
FN <- sum((A == 0) & (B == 1))
# 计算 FDR
if((TP + FP) > 0) {
FDR <- FP / (TP + FP)
} else {
FDR <- NA
warning("没有预测为阳性的样本（A = 1），无法计算 FDR。")
}
# 计算 Power
if(TP + FN > 0) {
Power <- TP / (TP + FN)
} else {
Power <- NA
warning("没有实际为阳性的样本（B = 1），无法计算 Power。")
}
# 计算 Accuracy
Accuracy <- (TP + TN) / (TP + FP + TN + FN)
# 打印结果
cat(sprintf("False Discovery Rate (FDR): %.2f%%\n", FDR * 100))
cat(sprintf("Power: %.2f%%\n", Power * 100))
cat(sprintf("Accuracy: %.2f%%\n", Accuracy * 100))
# 加载必要的包
library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.15
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
# print(correct_ratio_1)
A = pred_classes_G
B = as.numeric(q1_test$depressed)-1
# 计算 True Positives (TP)、False Positives (FP)、True Negatives (TN)、False Negatives (FN)
TP <- sum((A == 1) & (B == 1))
FP <- sum((A == 1) & (B == 0))
TN <- sum((A == 0) & (B == 0))
FN <- sum((A == 0) & (B == 1))
# 计算 FDR
if((TP + FP) > 0) {
FDR <- FP / (TP + FP)
} else {
FDR <- NA
warning("没有预测为阳性的样本（A = 1），无法计算 FDR。")
}
# 计算 Power
if(TP + FN > 0) {
Power <- TP / (TP + FN)
} else {
Power <- NA
warning("没有实际为阳性的样本（B = 1），无法计算 Power。")
}
# 计算 Accuracy
Accuracy <- (TP + TN) / (TP + FP + TN + FN)
# 打印结果
cat(sprintf("False Discovery Rate (FDR): %.2f%%\n", FDR * 100))
cat(sprintf("Power: %.2f%%\n", Power * 100))
cat(sprintf("Accuracy: %.2f%%\n", Accuracy * 100))
# 加载必要的包
library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.12
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
# print(correct_ratio_1)
A = pred_classes_G
B = as.numeric(q1_test$depressed)-1
# 计算 True Positives (TP)、False Positives (FP)、True Negatives (TN)、False Negatives (FN)
TP <- sum((A == 1) & (B == 1))
FP <- sum((A == 1) & (B == 0))
TN <- sum((A == 0) & (B == 0))
FN <- sum((A == 0) & (B == 1))
# 计算 FDR
if((TP + FP) > 0) {
FDR <- FP / (TP + FP)
} else {
FDR <- NA
warning("没有预测为阳性的样本（A = 1），无法计算 FDR。")
}
# 计算 Power
if(TP + FN > 0) {
Power <- TP / (TP + FN)
} else {
Power <- NA
warning("没有实际为阳性的样本（B = 1），无法计算 Power。")
}
# 计算 Accuracy
Accuracy <- (TP + TN) / (TP + FP + TN + FN)
# 打印结果
cat(sprintf("False Discovery Rate (FDR): %.2f%%\n", FDR * 100))
cat(sprintf("Power: %.2f%%\n", Power * 100))
cat(sprintf("Accuracy: %.2f%%\n", Accuracy * 100))
# 加载必要的包
library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.10
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
# print(correct_ratio_1)
A = pred_classes_G
B = as.numeric(q1_test$depressed)-1
# 计算 True Positives (TP)、False Positives (FP)、True Negatives (TN)、False Negatives (FN)
TP <- sum((A == 1) & (B == 1))
FP <- sum((A == 1) & (B == 0))
TN <- sum((A == 0) & (B == 0))
FN <- sum((A == 0) & (B == 1))
# 计算 FDR
if((TP + FP) > 0) {
FDR <- FP / (TP + FP)
} else {
FDR <- NA
warning("没有预测为阳性的样本（A = 1），无法计算 FDR。")
}
# 计算 Power
if(TP + FN > 0) {
Power <- TP / (TP + FN)
} else {
Power <- NA
warning("没有实际为阳性的样本（B = 1），无法计算 Power。")
}
# 计算 Accuracy
Accuracy <- (TP + TN) / (TP + FP + TN + FN)
# 打印结果
cat(sprintf("False Discovery Rate (FDR): %.2f%%\n", FDR * 100))
cat(sprintf("Power: %.2f%%\n", Power * 100))
cat(sprintf("Accuracy: %.2f%%\n", Accuracy * 100))
# 加载必要的包
library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.08
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
# print(correct_ratio_1)
A = pred_classes_G
B = as.numeric(q1_test$depressed)-1
# 计算 True Positives (TP)、False Positives (FP)、True Negatives (TN)、False Negatives (FN)
TP <- sum((A == 1) & (B == 1))
FP <- sum((A == 1) & (B == 0))
TN <- sum((A == 0) & (B == 0))
FN <- sum((A == 0) & (B == 1))
# 计算 FDR
if((TP + FP) > 0) {
FDR <- FP / (TP + FP)
} else {
FDR <- NA
warning("没有预测为阳性的样本（A = 1），无法计算 FDR。")
}
# 计算 Power
if(TP + FN > 0) {
Power <- TP / (TP + FN)
} else {
Power <- NA
warning("没有实际为阳性的样本（B = 1），无法计算 Power。")
}
# 计算 Accuracy
Accuracy <- (TP + TN) / (TP + FP + TN + FN)
# 打印结果
cat(sprintf("False Discovery Rate (FDR): %.2f%%\n", FDR * 100))
cat(sprintf("Power: %.2f%%\n", Power * 100))
cat(sprintf("Accuracy: %.2f%%\n", Accuracy * 100))
# 加载必要的包
library(dplyr)
library(ggplot2)
# 假设你的训练集为 train_data，测试集为 q1_test
q1_test <- q1_test[complete.cases(q1_test), ]
q1_test$DBQ700 <- factor(q1_test$DBQ700, levels = c("1","2", "3", "4", "5"))
q1_test$DBQ197 <- factor(q1_test$DBQ197, levels = c("0","1", "2", "3", "4"))
# 使用 model.matrix 生成训练集的哑变量
# x_train <- model.matrix(~ DBQ700 + DBQ197, data = train_data)[, -1]  # 去掉截距
# 使用 model.matrix 生成测试集的哑变量
x_test <- model.matrix(~ DBQ700 + DBQ197 -1, data = q1_test)[,-1]  # 注意：不需要包含响应变量
# 加载必要的包
library(glmnet)
# 假设你已经训练了 lasso_model，使用 x_train 和 y_train
# 例如：
# lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
# 预测概率
pred_probs_G <- predict.glm(step_model,newdata = q1_test,type = "response")
pred_probs_L <- predict(lasso_model, newx = x_test, type = "response")
pred_probs_R <- predict(ridge_model, newx = x_test, type = "response")
# 将预测概率转换为类别
threshold <- 0.075
correct_ratio_1 <- array(dim = 3,dimnames = list(c("step","lasso","ridge")))
pred_classes_G <- ifelse(pred_probs_G > threshold, 1, 0)
correct_ratio_1[1] <- sum(abs(pred_classes_G-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_G)
pred_classes_L <- ifelse(pred_probs_L > threshold, 1, 0)
correct_ratio_1[2] <- sum(abs(pred_classes_L-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_L)
pred_classes_R <- ifelse(pred_probs_R > threshold, 1, 0)
correct_ratio_1[3] <- sum(abs(pred_classes_R-(as.numeric(q1_test$depressed)-1)))/length(pred_classes_R)
# print(correct_ratio_1)
A = pred_classes_G
B = as.numeric(q1_test$depressed)-1
# 计算 True Positives (TP)、False Positives (FP)、True Negatives (TN)、False Negatives (FN)
TP <- sum((A == 1) & (B == 1))
FP <- sum((A == 1) & (B == 0))
TN <- sum((A == 0) & (B == 0))
FN <- sum((A == 0) & (B == 1))
# 计算 FDR
if((TP + FP) > 0) {
FDR <- FP / (TP + FP)
} else {
FDR <- NA
warning("没有预测为阳性的样本（A = 1），无法计算 FDR。")
}
# 计算 Power
if(TP + FN > 0) {
Power <- TP / (TP + FN)
} else {
Power <- NA
warning("没有实际为阳性的样本（B = 1），无法计算 Power。")
}
# 计算 Accuracy
Accuracy <- (TP + TN) / (TP + FP + TN + FN)
# 打印结果
cat(sprintf("False Discovery Rate (FDR): %.2f%%\n", FDR * 100))
cat(sprintf("Power: %.2f%%\n", Power * 100))
cat(sprintf("Accuracy: %.2f%%\n", Accuracy * 100))
